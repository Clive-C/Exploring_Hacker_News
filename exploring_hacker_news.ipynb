{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "810b5fff621999477888472bd677d155adb8432335ba43a8724e9627503460a8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exploring Hacker News Posts\n",
    "## The project will explore the Hacker News Posts and determine whether the Hacker News community has more average comments on posts that asks a question, or user submitted posts that showcases a project, project or just generally something interesting.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "open_file = open('hacker_news.csv',  encoding='utf-8')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:5]) #Displays the first 5 rows of the list to determine what kind of data we are dealing with."
   ]
  },
  {
   "source": [
    "After determining the first row contains the Header with the subsequent rows containing the actual data, we will remove the first row from the list 'hn' and put it into its own 'header'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(hn[:5]) # re-displaying the list to make sure we have eliminated the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print(headers) #prints the header of the list of data"
   ]
  },
  {
   "source": [
    "After we have separated the data we want to work with from the Header, we then proceed to separate each post according to their titles. We create 3 different categories: Ask Post, Show Post and Other Post, depending on whether the title of the post begins with \"ask hn\", \"show hn\", or if either of these are absent we will categorize the post to the Other Post category. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of Ask hn Posts: 9139\n# of Show hn Posts: 10158\n# of Other hn Posts: 273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'): # title.lower() standarizes the title so we can match it to a lower case version of the title\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"# of Ask hn Posts:\", len(ask_posts))\n",
    "print(\"# of Show hn Posts:\", len(show_posts))\n",
    "print(\"# of Other hn Posts:\", len(other_posts))"
   ]
  },
  {
   "source": [
    "After running the filter through the whole list of data, we can see there are 9139 posts that are \"ask posts\", 10158 posts that are \"show posts\" and 273822 posts that are neither \"ask\" nor \"show\" posts. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Having separated the lists of Ask HN posts and Show HN posts, we then are able to figure out the average number of comments for each of these Post categories."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The average # of Ask Posts is : 10.39\nThe average # of Show Posts is : 4.89\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "avg_ask_comments = round(total_ask_comments / len(ask_posts),2)\n",
    "\n",
    "print(\"The average # of Ask Posts is :\", avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = round(total_show_comments / len(show_posts),2)\n",
    "\n",
    "print(\"The average # of Show Posts is :\", avg_show_comments)"
   ]
  },
  {
   "source": [
    "As we can see, ask posts, on average, receives more comments than show posts. Moving forward, we will continue our analysis focused on ask posts since they are more likely to receive comments. \n",
    "\n",
    "The next step in our analysis will be to determine if asks posts created at a certain time are more likely to attract comments. To do this, will we calculate the amount of ask posts create in each hour of the day and figure our the average number of comments received at each hour."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['9/26/2016 2:53', 7], ['9/26/2016 1:17', 3], ['9/25/2016 22:57', 0], ['9/25/2016 22:48', 3], ['9/25/2016 21:50', 2]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "#created a list of list that consists of two elements: the date/time the post was create and the number of comments\n",
    "for ask in ask_posts:\n",
    "    created_at = ask[6]\n",
    "    num_comments = int(ask[4])\n",
    "    result_list.append([created_at, num_comments]) \n",
    "\n",
    "print(result_list[:5]) #printed the first 5 lines for verification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'00': 301, '01': 282, '02': 269, '03': 271, '04': 243, '05': 209, '06': 234, '07': 226, '08': 257, '09': 222, '10': 282, '11': 312, '12': 342, '13': 444, '14': 513, '15': 646, '16': 579, '17': 587, '18': 614, '19': 552, '20': 510, '21': 518, '22': 383, '23': 343}\n{'00': 2277, '01': 2089, '02': 2996, '03': 2154, '04': 2360, '05': 1838, '06': 1587, '07': 1585, '08': 2362, '09': 1477, '10': 3013, '11': 2797, '12': 4234, '13': 7245, '14': 4972, '15': 18525, '16': 4466, '17': 5547, '18': 4877, '19': 3954, '20': 4462, '21': 4500, '22': 3372, '23': 2297}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date_time = row[0]\n",
    "    date_time = dt.datetime.strptime(date_time, \"%m/%d/%Y %H:%M\")\n",
    "    post_time = date_time.strftime(\"%H\")\n",
    "\n",
    "    if post_time not in counts_by_hour:\n",
    "        counts_by_hour[post_time] = 1\n",
    "        comments_by_hour[post_time] = int(row[1])\n",
    "    else:\n",
    "        counts_by_hour[post_time] += 1\n",
    "        comments_by_hour[post_time] += int(row[1])\n",
    "\n",
    "sorted_counts_by_hour = {}\n",
    "sorted_comments_by_hour ={}\n",
    "\n",
    "sorted_list = sorted(counts_by_hour)\n",
    "\n",
    "for each_hour in sorted_list:\n",
    "    sorted_counts_by_hour[each_hour] = counts_by_hour[each_hour]\n",
    "    sorted_comments_by_hour[each_hour] = comments_by_hour[each_hour]\n",
    "\n",
    "print(sorted_counts_by_hour)\n",
    "print(sorted_comments_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['00', 7.5647840531561465], ['01', 7.407801418439717], ['02', 11.137546468401487], ['03', 7.948339483394834], ['04', 9.7119341563786], ['05', 8.794258373205741], ['06', 6.782051282051282], ['07', 7.013274336283186], ['08', 9.190661478599221], ['09', 6.653153153153153], ['10', 10.684397163120567], ['11', 8.96474358974359], ['12', 12.380116959064328], ['13', 16.31756756756757], ['14', 9.692007797270955], ['15', 28.676470588235293], ['16', 7.713298791018998], ['17', 9.449744463373083], ['18', 7.94299674267101], ['19', 7.163043478260869], ['20', 8.749019607843136], ['21', 8.687258687258687], ['22', 8.804177545691905], ['23', 6.696793002915452]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the average number of comments per post for each hour of the day\n",
    "\n",
    "avg_by_hour = []\n",
    "for each_hour in sorted_list:\n",
    "    avg_comment = comments_by_hour[each_hour] / counts_by_hour[each_hour]\n",
    "    avg_by_hour.append([each_hour, avg_comment])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n15:00: 28.68 average comments per post\n13:00: 16.32 average comments per post\n12:00: 12.38 average comments per post\n02:00: 11.14 average comments per post\n10:00: 10.68 average comments per post\nWorst 5 Hours for Ask Posts Comments\n01:00: 7.41 average comments per post\n19:00: 7.16 average comments per post\n07:00: 7.01 average comments per post\n06:00: 6.78 average comments per post\n23:00: 6.70 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Next we are going to change position of the hour and the avg in order to use the sort method to determine the top highest average to lowest average\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for key in avg_by_hour:\n",
    "    swap_avg_by_hour.append([key[1],key[0]])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "#Printing the \"Top 5 Hours for Ask Posts Comments\"\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour_object = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour_object = hour_object.strftime(\"%H:%M\")\n",
    "    result_string = \"{}: {:.2f} average comments per post\".format(hour_object, row[0])\n",
    "    print(result_string)\n",
    "\n",
    "print(\"Worst 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap[-6:-1]:\n",
    "    hour_object = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour_object = hour_object.strftime(\"%H:%M\")\n",
    "    result_string = \"{}: {:.2f} average comments per post\".format(hour_object, row[0])\n",
    "    print(result_string)\n",
    "\n"
   ]
  },
  {
   "source": [
    "In conclusion, from the given data, when users submits Ask Posts at 3PM, it generates on average, the most comments with Ask Posts submitted at 11pm having the worst average comments per post."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}